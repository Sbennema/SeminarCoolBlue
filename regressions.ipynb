{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "import KTBoost.KTBoost as KTBoost\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_dir should be the direction to \n",
    "main_dir = sys.path[0]\n",
    "\n",
    "dir_spotlift = main_dir + r'\\spotlifts\\BSTS_4min'\n",
    "dir_X = main_dir + r'\\X_matrix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spotlift_group(X, y):\n",
    "    df = X.copy()\n",
    "    df['y']  = None\n",
    "    for idx,row in df[['date_time','post_eff']].iterrows():\n",
    "        dates = pd.date_range(start=row[0], end =row[1], freq='min')\n",
    "        df.loc[idx, ['y']]= y[y['date_time'].isin(dates)].iloc[:,[1]].sum().values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final data selection\n",
    "def prep_dataset(X_matrix, country, medium):\n",
    "    filename = r'\\lift_' + country + '_' + medium + '_case1_4min.csv'\n",
    "    DataSet = pd.read_csv(dir_spotlift + filename, sep=';', index_col = 0, parse_dates=['time'])\n",
    "    DataSet.columns = ['date_time', 'Spotlift']\n",
    "    DataSet.loc[(DataSet['Spotlift']<0) | (DataSet['Spotlift'].isna()) , 'Spotlift']= 0\n",
    "    return spotlift_group(X_matrix,DataSet[['date_time', 'Spotlift']])\n",
    "\n",
    "X_nl = pd.read_csv(dir_X + '\\X_nl_4min.csv', index_col='ad_group')\n",
    "X_be = pd.read_csv(dir_X + '\\X_be_4min.csv', index_col='ad_group')\n",
    "\n",
    "NL_web = prep_dataset(X_nl, 'nl', 'web')\n",
    "NL_app = prep_dataset(X_nl, 'nl', 'app')\n",
    "BE_web = prep_dataset(X_be, 'be', 'web')\n",
    "BE_app = prep_dataset(X_be, 'be', 'app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the importances of Neural Nets using the Connection Weights approach\n",
    "# Eventually, this is not used in our research------------------------------------------------------------------------------\n",
    "def conn_weights(model):\n",
    "    for layer in reversed(model.layers): \n",
    "        gew = layer.get_weights()[0]\n",
    "        if gew.shape[1]==1:\n",
    "            new_gew = gew\n",
    "            continue\n",
    "        else:\n",
    "            new_gew = np.dot(gew,new_gew)\n",
    "    return new_gew\n",
    "\n",
    "# Function to display predictions for the different models that are used----------------------------------------------------\n",
    "def disp_preds(model, X_train, X_test, y_train, y_test, new=False, ols= False):\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10,10))\n",
    "    if ols!=False:\n",
    "        y_pred = np.dot(X_train,ols.params)\n",
    "    else:\n",
    "        y_pred = model.predict(X_train)\n",
    "    if new:\n",
    "        test = pd.DataFrame([y_train,y_pred]).transpose()\n",
    "    else:\n",
    "        test = pd.DataFrame([y_train,np.concatenate(y_pred,axis=0)]).transpose()\n",
    "    test.columns =['real','pred']\n",
    "    test.plot(ax=axes[0,0], style='.-')\n",
    "\n",
    "    diff = test['real']-test['pred']\n",
    "    diff.plot(ax=axes[0,1], style='.-')\n",
    "    if ols!=False:\n",
    "        y_pred = np.dot(X_test,ols.params)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "    if new:\n",
    "        test = pd.DataFrame([y_test,y_pred]).transpose()\n",
    "    else:\n",
    "        test = pd.DataFrame([y_test,np.concatenate(y_pred,axis=0)]).transpose()\n",
    "    test.columns =['real','pred']\n",
    "    test.plot(ax=axes[1,0], style='.-')\n",
    "\n",
    "    diff = test['real']-test['pred']\n",
    "    diff.plot(ax=axes[1,1], style='.-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net(X_train,X_test,y_train,y_test, columns, disp):\n",
    "    input_layer = X_train.shape[1]\n",
    "    hidden_first=20\n",
    "    hidden_second = 20\n",
    "    act_fun = 'elu'\n",
    "    act_fun_out = 'elu'\n",
    "    bias = False\n",
    "    metrics='MeanSquaredError'\n",
    "    epochs = 18\n",
    "    \n",
    "    model = Sequential()\n",
    "    # input layer\n",
    "    model.add(Dense(hidden_first, input_dim=input_layer, activation=act_fun, use_bias=bias))\n",
    "    # hidden layers\n",
    "    model.add(Dense(hidden_second, activation=act_fun, use_bias=bias))\n",
    "    model.add(Dense(hidden_second, activation=act_fun, use_bias=bias))\n",
    "    # output layer\n",
    "    model.add(Dense(1, activation=act_fun_out, use_bias=bias))\n",
    "    model.compile(loss=metrics, optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "    # predict and plot including importances\n",
    "    history = model.fit(X_train, y_train,validation_data = (X_test,y_test), epochs=epochs, verbose=0)\n",
    "       \n",
    "    pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, pred)\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    display('MSE Neural Network: ' + str(mse))\n",
    "    \n",
    "    if disp==True:\n",
    "        # print the train and test MSE\n",
    "        pd.DataFrame(history.history).drop(['loss', 'val_loss'],axis=1).plot()\n",
    "        plt.show()\n",
    "        # Plot the predictions\n",
    "        disp_preds(model, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # Importances---NOT USED\n",
    "#     connection_weights = conn_weights(model)\n",
    "#     frame = pd.DataFrame(connection_weights, index = columns)\n",
    "#     frame_abs = frame.reindex(frame[0].abs().sort_values(ascending=False).index)\n",
    "#     frame_norm = frame.sort_values(0, ascending=False)\n",
    "#     print('neural importance')\n",
    "#     display(frame_norm)\n",
    "    return mse, mae\n",
    "# --------------------------------------------------------------------------------------------------------------------------\n",
    "def ols_reg(X_train,X_test,y_train,y_test, columns, disp):\n",
    "    model = sm.OLS(y_train, X_train)\n",
    "    results = model.fit()\n",
    "#     print(results.summary(xname=columns))\n",
    "    pred = np.dot(X_test,results.params)\n",
    "    mse = mean_squared_error(y_test, pred)\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    display('MSE ols: ' + str(mse))\n",
    "    \n",
    "    if disp==True:\n",
    "        # Plot the predictions\n",
    "        disp_preds(model, X_train, X_test, y_train, y_test, True, results)\n",
    "    return mse, mae\n",
    "# --------------------------------------------------------------------------------------------------------------------------\n",
    "def rf_reg(X_train,X_test,y_train,y_test, columns, disp = False):\n",
    "    rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred = rf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, pred)\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    display('MSE Random Forest: ' + str(mse))\n",
    "    \n",
    "    if disp==True:\n",
    "        # Plot the predictions\n",
    "        disp_preds(rf, X_train, X_test, y_train, y_test, True)\n",
    "    return mse,mae\n",
    "# --------------------------------------------------------------------------------------------------------------------------\n",
    "def tobit_reg(X_train,X_test,y_train,y_test, columns, disp):\n",
    "    model = KTBoost.BoostingRegressor(loss='tobit',yl=10^-10,yu=10000)\n",
    "\n",
    "    # Train model\n",
    "    results = model.fit(X_train,y_train)\n",
    "\n",
    "    # Make prediction\n",
    "    pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, pred)\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    print('MSE Tobit : ' + str(mse))\n",
    "\n",
    "    if disp==True:\n",
    "        # Plot the predictions\n",
    "        disp_preds(model, X_train, X_test, y_train, y_test, True)\n",
    "    return mse,mae\n",
    "# --------------------------------------------------------------------------------------------------------------------------\n",
    "def lasso_reg(X_train,X_test,y_train,y_test, columns, disp):\n",
    "    model = linear_model.ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1],\n",
    "                                      fit_intercept=False, normalize=True,random_state=0)\n",
    "    results = model.fit(X_train,y_train)\n",
    "    coefs = pd.DataFrame({'Coefficient': results.coef_}, index=columns)\n",
    "    coefs = coefs.reindex(coefs.Coefficient.abs().sort_values(ascending=False).index)\n",
    "    display(coefs)\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    pred_train = model.predict(X_train)\n",
    "    mse = mean_squared_error(y_test, pred)\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    print('MSE Lasso : ' + str(mse))\n",
    "    print('R2 score: ' + str(r2_score(y_train, pred_train)))\n",
    "    print('l1-ratio: ' + str(model.l1_ratio_))\n",
    "    print('Alpha: '+str(results.alpha_))\n",
    "    \n",
    "    if disp==True:\n",
    "        # Plot the predictions\n",
    "        disp_preds(model, X_train, X_test, y_train, y_test, True)\n",
    "    return mse,mae\n",
    "# --------------------------------------------------------------------------------------------------------------------------\n",
    "def compares(X_train,X_test,y_train,y_test, columns, models, disp):\n",
    "    mse_rf, mse_ols, mse_tobit, mse_ann, mse_lasso = None,None,None,None,None\n",
    "    mae_rf, mae_ols, mae_tobit, mae_ann, mae_lasso = None,None,None,None,None\n",
    "    # Random Forest-------------------------------------------------------------------\n",
    "    if 'rf' in models:\n",
    "        mse_rf, mae_rf = rf_reg(X_train,X_test,y_train,y_test, columns, disp)\n",
    "    # OLS regression------------------------------------------------------------------\n",
    "    if 'ols' in models:\n",
    "        mse_ols, mae_ols = ols_reg(X_train,X_test,y_train,y_test, columns, disp)\n",
    "    # Tobit---------------------------------------------------------------------------\n",
    "    if 'tobit' in models:\n",
    "        mse_tobit, mae_tobit = tobit_reg(X_train,X_test,y_train,y_test, columns, disp)\n",
    "    # Neural network------------------------------------------------------------------\n",
    "    if 'ann' in models:\n",
    "        mse_ann, mae_ann = neural_net(X_train,X_test,y_train,y_test, columns, disp)\n",
    "    # Lasso---------------------------------------------------------------------------\n",
    "    if 'lasso' in models:\n",
    "        mse_lasso, mae_lasso = lasso_reg(X_train,X_test,y_train,y_test, columns, disp)\n",
    "    return [mse_rf, mse_ols, mse_tobit, mse_ann, mse_lasso,\n",
    "            mae_rf, mae_ols, mae_tobit, mae_ann, mae_lasso]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(data, scaler, drop_col=None, kfold=True, models = ['lasso'], disp=False):\n",
    "    #set random seed/state\n",
    "    seed_value = 309\n",
    "    tf.random.set_seed(seed_value)\n",
    "    \n",
    "    # normalize\n",
    "    X = data.drop(['date_time', 'y', 'post_eff'], axis=1)\n",
    "\n",
    "    if drop_col is not None:\n",
    "        X = X.drop(drop_col,axis=1)\n",
    "    columns = X.columns.tolist()\n",
    "\n",
    "    if scaler is not None:\n",
    "        if scaler== 'standard':\n",
    "            sc = StandardScaler()\n",
    "        elif scaler =='minmax':\n",
    "            sc = MinMaxScaler()\n",
    "        X = sc.fit_transform(X.values)\n",
    "    else:\n",
    "        X = X.to_numpy()\n",
    "    \n",
    "    # Add constant\n",
    "    X = sm.add_constant(X)    \n",
    "    columns.insert(0,'const')\n",
    "\n",
    "    y = data['y'].values\n",
    "    y = np.asarray(y).astype('float32')\n",
    "\n",
    "    if kfold:\n",
    "        # K-fold splits\n",
    "        kf = KFold(n_splits=5, random_state=456, shuffle=True)\n",
    "\n",
    "        temp = []\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            temp.append(compares(X_train,X_test, y_train, y_test, columns, models, disp))\n",
    "    else:\n",
    "        temp = []\n",
    "        # If it is not a k-fold, we use all the data to get the final model, we do not test anymore        \n",
    "        temp.append(compares(X,X, y, y, columns, models, disp))\n",
    "        \n",
    "    results = pd.concat([pd.DataFrame([i], columns=['rf_mse', 'ols_mse', 'tobit_mse', 'ann_mse', 'lasso_mse',\n",
    "                                                    'rf_mae', 'ols_mae', 'tobit_mae', 'ann_mae', 'lasso_mae']) for i in temp], ignore_index=True)\n",
    "    display(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Table 7: Model selection\n",
    "# To avoid multicollinearity, of each category, one feature is left out. Prime and the operators are not used anyway\n",
    "columns = ['operator_Talpa TV',\n",
    "           'operator_Ad Alliance',\n",
    "           'operator_Ster',\n",
    "           'prod_cat_wasmachines',  \n",
    "           'prime', \n",
    "           'duration_30 + 10 + 5', \n",
    "           'channel_Veronica',\n",
    "           'pos_break_Any Other Position']\n",
    "models = ['rf', 'ann', 'ols', 'tobit']\n",
    "results = ANN(NL_web, None, drop_col=columns, kfold =True, models = models, disp=False)\n",
    "\n",
    "display(results.mean(), results.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tabel 8,26 and 27: Elastic Net features the Netherlands\n",
    "columns = ['operator_Talpa TV',\n",
    "           'operator_Ad Alliance',\n",
    "           'operator_Ster',\n",
    "           'prime']\n",
    "results_nl_web = ANN(NL_web, None, drop_col=columns, kfold =False, models = ['lasso'], disp=False)\n",
    "results_nl_app = ANN(NL_app, None, drop_col=columns, kfold =False, models = ['lasso'], disp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tabel 28 and 29: Elastic Net features Belgium\n",
    "columns = ['operator_MEDIALAAN',\n",
    "           'operator_SBS',\n",
    "           'operator_TRANSFER',\n",
    "           'prime']\n",
    "results_be_web = ANN(BE_web, None, drop_col=columns, kfold =False, models = ['lasso'], disp=False)\n",
    "results_be_app = ANN(BE_app, None, drop_col=columns, kfold =False, models = ['lasso'], disp=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
