{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spotlift_group(X, y):\n",
    "    df = X.copy()\n",
    "    df['y']  = None\n",
    "    for idx,row in df[['date_time','post_eff']].iterrows():\n",
    "        dates = pd.date_range(start=row[0], end =row[1], freq='min')\n",
    "        df.loc[idx, ['y']]= y[y['date_time'].isin(dates)].iloc[:,[1]].sum().values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the direction to the main directory\n",
    "direct = sys.path[0]\n",
    "\n",
    "dir_greedy = direct + r'\\spotlifts\\Greedy'\n",
    "dir_BSTS = direct + r'\\spotlifts\\BSTS_4min'\n",
    "dir_save = direct + r'\\results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for post-effect:\n",
    "def post_effects(case):\n",
    "    dates = pd.date_range(start='2019-01-01 00:00:00', end ='2019-06-30 23:59:00', freq='min')\n",
    "    total_list = {}\n",
    "    main_folder = dir_greedy\n",
    "    folder = os.path.join(main_folder, case, r'All visits')\n",
    "    sets = {}\n",
    "    matrices = {}\n",
    "    for filename in os.listdir(folder):\n",
    "        post_eff = int(filename[-5])\n",
    "        title = str(post_eff)+'min'\n",
    "\n",
    "        if title == '0min':\n",
    "            post_eff = 10\n",
    "            title = '10min'\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        DataSet = pd.read_csv(file_path, usecols=['Spotlift'])\n",
    "        DataSet['date_time'] = dates\n",
    "        if case[:2]=='NL':\n",
    "            X_dir = direct + r'\\X_matrix\\X_nl_' + title + '.csv'\n",
    "        else:\n",
    "            X_dir = direct + r'\\X_matrix\\X_be_' + title + '.csv'\n",
    "        X_matrix = pd.read_csv(X_dir, index_col='ad_group')\n",
    "        lift = spotlift_group(X_matrix,DataSet[['date_time','Spotlift']])\n",
    "        sets[title] = DataSet\n",
    "        matrices[title]  = lift\n",
    "\n",
    "        neg_mins = len(DataSet[DataSet['Spotlift']<0])/len(DataSet[DataSet['Spotlift']!=0])*100\n",
    "        neg_lifts = len(lift[lift['y']<0])/len(lift)*100\n",
    "        positive_lifts = DataSet[DataSet['Spotlift']>0]['Spotlift'].sum()/post_eff\n",
    "        total_lifts = DataSet['Spotlift'].sum()/post_eff\n",
    "\n",
    "        total_list[title] = [neg_mins, neg_lifts, positive_lifts, total_lifts]\n",
    "\n",
    "    result = pd.DataFrame.from_dict(total_list, orient='index',\n",
    "                           columns = ['% neg. ad_group', '% neg. spotlifts', 'positive', 'all']).sort_index()\n",
    "    display(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 5, 14-17\n",
    "post_eff_NL_Web = post_effects('NL_Web')\n",
    "post_eff_NL_App = post_effects('NL_App')\n",
    "post_eff_BE_Web = post_effects('BE_Web')\n",
    "post_eff_BE_App = post_effects('BE_App')\n",
    "\n",
    "post_eff_NL_Web.to_excel(dir_save + r'\\post_eff_NL_Web.xlsx')\n",
    "post_eff_NL_App.to_excel(dir_save + r'\\post_eff_NL_App.xlsx')\n",
    "post_eff_BE_Web.to_excel(dir_save + r'\\post_eff_BE_Web.xlsx')\n",
    "post_eff_BE_App.to_excel(dir_save + r'\\post_eff_BE_App.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 6, 18-25\n",
    "# BTST 4 min----------------------------------------------------------------------------------------------------------------\n",
    "dates = pd.date_range(start='2019-01-01 00:00:00', end ='2019-06-30 23:59:00', freq='min')\n",
    "\n",
    "folder = dir_BSTS\n",
    "total_list = {}\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "    post_eff = 4\n",
    "    country = filename[5:7]\n",
    "    medium = filename[8:11]\n",
    "    title = filename[5:17]\n",
    "    case = filename[16]\n",
    "\n",
    "    file_path = os.path.join(folder, filename)\n",
    "\n",
    "    DataSet = pd.read_csv(file_path, sep=';', usecols=['lift'])\n",
    "    DataSet.columns = ['Spotlift']\n",
    "    DataSet['date_time'] = dates\n",
    "\n",
    "    if country == 'nl':\n",
    "        X_dir = direct + r'\\X_matrix\\X_nl_4min.csv'\n",
    "    else:\n",
    "        X_dir = direct + r'\\X_matrix\\X_be_4min.csv'     \n",
    "    X_matrix = pd.read_csv(X_dir, index_col='ad_group')\n",
    "    \n",
    "    neg_mins = len(DataSet[DataSet['Spotlift']<0])/len(DataSet[DataSet['Spotlift'].notna()])*100\n",
    "    neg_lifts = DataSet[DataSet['Spotlift']>0]['Spotlift'].median()\n",
    "    mad = stats.median_absolute_deviation(DataSet[DataSet['Spotlift']>0]['Spotlift'])\n",
    "    sum_pos = DataSet[DataSet['Spotlift']>0]['Spotlift'].sum()\n",
    "    \n",
    "    total_list[title] = [neg_mins, neg_lifts, mad, sum_pos]\n",
    "\n",
    "result = pd.DataFrame.from_dict(total_list, orient='index',\n",
    "                       columns = ['% neg. mins', 'median', 'mad', 'sum pos spotlift'])\n",
    "display(result)  \n",
    "\n",
    "result.to_excel(dir_save+r'\\cases_BSTS_4min.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Greedy 4 min----------------------------------------------------------------------------------------------------------------\n",
    "countries = ['NL', 'BE']\n",
    "mediums = ['App', 'Web']\n",
    "cases = ['All visits', 'No paid visits', 'Direct and search visits', 'Direct visits']\n",
    "\n",
    "folder = dir_greedy\n",
    "total_list = {}\n",
    "\n",
    "for c in countries:\n",
    "    for m in mediums:\n",
    "        for idx,ca in enumerate(cases):\n",
    "            version = c + '_' + m\n",
    "            file_path = os.path.join(folder, version, ca, '4.csv')\n",
    "            title = version + '_case' + str(idx+1)\n",
    "\n",
    "            DataSet = pd.read_csv(file_path, usecols=['Spotlift'])\n",
    "            DataSet['date_time'] = dates\n",
    "\n",
    "            if country == 'NL':\n",
    "                X_dir = direct + r'\\X_matrix\\X_nl_4min.csv'\n",
    "            else:\n",
    "                X_dir = direct + r'\\X_matrix\\X_be_4min.csv'     \n",
    "            X_matrix = pd.read_csv(X_dir, index_col='ad_group')\n",
    "            \n",
    "            neg_mins = len(DataSet[DataSet['Spotlift']<0])/len(DataSet[DataSet['Spotlift']!=0])*100\n",
    "            neg_lifts = DataSet[DataSet['Spotlift']>0]['Spotlift'].median()\n",
    "            mad = stats.median_absolute_deviation(DataSet[DataSet['Spotlift']>0]['Spotlift'])\n",
    "            sum_pos = DataSet[DataSet['Spotlift']>0]['Spotlift'].sum()\n",
    "    \n",
    "            total_list[title] = [neg_mins, neg_lifts, mad, sum_pos]\n",
    "        \n",
    "result = pd.DataFrame.from_dict(total_list, orient='index',\n",
    "                       columns = ['% neg. mins', 'median', 'mad', 'sum pos spotlift'])\n",
    "display(result) \n",
    "result.to_excel(dir_save+r'\\cases_GREEDY_4min.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
