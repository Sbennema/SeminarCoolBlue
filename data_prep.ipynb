{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import category_encoders as ce\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the direction to the main directory\n",
    "direct = sys.path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Coolblue datafiles\n",
    "traffic_data = pd.read_csv(direct+r'\\Coolblue_datasets\\traffic_data', parse_dates=['date_time'],\n",
    "                                      index_col=['date_time'])\n",
    "broadcasting_data = pd.read_csv(direct+r'\\Coolblue_datasets\\broadcasting_data', parse_dates=[['date', 'time']])\n",
    "\n",
    "\n",
    "# For each case, the datapreparation has to be done individually------------------------------------------------------------\n",
    "traffic_datasets = []\n",
    "\n",
    "# first filter out the push notifications and bounces\n",
    "# CASE 1:-------------------------------------------------------------------------------------------------------------------\n",
    "traffic_datasets.append(traffic_data[(traffic_data['visit_source']!='push notification') & (traffic_data['bounces']!=1)])\n",
    "\n",
    "\n",
    "# CASE 2:-------------------------------------------------------------------------------------------------------------------\n",
    "traffic_datasets.append(traffic_data[(traffic_data['visit_source']!='push notification') &\n",
    "                            (traffic_data['visit_source']!='paid search') &\n",
    "                            (traffic_data['bounces']!=1)])\n",
    "\n",
    "# CASE 3:-------------------------------------------------------------------------------------------------------------------\n",
    "traffic_datasets.append(traffic_data[(traffic_data['visit_source']=='direct') &\n",
    "                           (traffic_data['bounces']!=1)])\n",
    "\n",
    "# CASE 4:-------------------------------------------------------------------------------------------------------------------\n",
    "traffic_datasets.append(traffic_data[(traffic_data['visit_source']!='push notification') &\n",
    "                            (traffic_data['visit_source']!='paid search') &\n",
    "                            (traffic_data['visit_source']!='other') &\n",
    "                            (traffic_data['bounces']!=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions that are used to build datasets with the spotlift---------------------------------------------------------------\n",
    "\n",
    "# There are some outliers that looks like they are actually caused by push notifications,-----------------------------------\n",
    "# therefore, they should not be included\n",
    "def filter_outliers(data):\n",
    "    new = data\n",
    "    new.loc[new['visits_index']>0.1, 'visits_index']=0\n",
    "    return new\n",
    "\n",
    "# adjust noon observations-------------------------------------------------------------------------------------------\n",
    "# It appears that at 23.59h there is an unexplainable peak. It might be that this is the result of all unassigned visits of\n",
    "# the day that therefore ends in the last minute. 23.59h will be the average of 23.58h and 00.00h, and the other visits \n",
    "# will be spread over the day\n",
    "def adj_midnight(data, perc):\n",
    "    start_day = data.index.min()\n",
    "    end_day = data.index.max()\n",
    "    data = data.reset_index()\n",
    "    noons = data[data['date_time'].dt.time==datetime.time(0,0)]\n",
    "    \n",
    "    for idx, row in noons.iterrows():\n",
    "        curr = row['visits_index']\n",
    "        if curr !=0:\n",
    "            if idx ==0:\n",
    "                average = data.loc[idx+1, 'visits_index']\n",
    "                diff = curr - average\n",
    "                if diff/curr >0.1:\n",
    "                    data.loc[idx, 'visits_index'] = average     #Only correct first evaluation\n",
    "            else:\n",
    "                average = (data.loc[idx-1, 'visits_index'] + data.loc[idx+1, 'visits_index'])/2\n",
    "                diff = curr - average\n",
    "                if diff/curr >perc:\n",
    "                    #Add 1/1439 of the difference to each observation of the day and change noon in average\n",
    "                    data.loc[idx-1439:idx-1, 'visits_index']= data.loc[idx-1439:idx-1, 'visits_index'] +diff/1439\n",
    "                    data.loc[idx, 'visits_index'] = average\n",
    "    return data.set_index('date_time')\n",
    "\n",
    "# Main function to build the dependend variable-----------------------------------------------------------------------------\n",
    "def prep_data(data,broadcasting,country,medium,time_effect):\n",
    "    relevant = data.copy()\n",
    "    dates = pd.date_range(start=relevant.index.min(), end =relevant.index.max(), freq='min')\n",
    "    dates = pd.DataFrame({'visits_index': 0}, index = dates)\n",
    "    dates.index.name = 'date_time'\n",
    "    \n",
    "    relevant_nl = relevant[(relevant['country']== country) & (relevant['medium']== medium)]\n",
    "    \n",
    "    # Filter outliers if medium is app\n",
    "    if medium =='app':\n",
    "        relevant_nl = filter_outliers(relevant_nl)\n",
    "\n",
    "    visits_nl = relevant_nl.groupby('date_time').sum()['visits_index']\n",
    "    visits_nl = pd.DataFrame(visits_nl)\n",
    "\n",
    "    final_nl = pd.merge(dates, visits_nl, left_on = 'date_time', right_on = 'date_time', how='left').sum(axis=1)\n",
    "    final_nl = pd.DataFrame(final_nl, columns = ['visits_index'])\n",
    "    final_nl['ads'] = 0\n",
    "\n",
    "    # The length of spots are a minimum of 30seconds and maximum of 45 seconds, which means less than a minute\n",
    "    # Adjustment: accuracy of date_time to minutes, to match them with 'final'\n",
    "    broad_nl = broadcasting[broadcasting['country']==country]\n",
    "\n",
    "    ads_starts_nl = broad_nl['date_time'].astype('datetime64[m]').sort_values().drop_duplicates() #all ads starting times\n",
    "    ads_dates = dates.rename(columns={'visits_index': 'ads'}) #all timestamps\n",
    "\n",
    "    last_min = visits_nl.index.max()\n",
    "    boundary = last_min-pd.Timedelta(minutes=time_effect)\n",
    "\n",
    "    # loop over all starting times and add the time_effect, store these in ads_dates\n",
    "    for ad in ads_starts_nl:\n",
    "        if ad<boundary:\n",
    "            effect = pd.date_range(start=ad, periods = time_effect, freq='min')\n",
    "            ads_dates.loc[effect, 'ads'] = 1\n",
    "        else:\n",
    "            effect = pd.date_range(start=ad, periods = ((last_min-ad).total_seconds()/60+1), freq='min')\n",
    "            ads_dates.loc[effect, 'ads'] = 1\n",
    "            break\n",
    "\n",
    "    final_nl['ads'] = ads_dates['ads']\n",
    "    final_nl = adj_midnight(final_nl,0)\n",
    "    \n",
    "    #Add Column with numbers of ads that started that minute\n",
    "    broad_nl['date_time'] = broad_nl['date_time'].astype('datetime64[m]')\n",
    "    ads_starts = broad_nl.groupby('date_time')['date_time'].count()\n",
    "    final_nl['start_ad'] = 0\n",
    "    final_nl.loc[list(ads_starts.index), 'start_ad'] = ads_starts.values\n",
    "    \n",
    "    return final_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEXT THE X-MATRIX WILL BE CREATED\n",
    "# There are two ways, one way that will aggregate features if multiple adds are aggregated: build_X()\n",
    "# the second way is just the features per advertisement: build_X_blocks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_matrix based on grouped adds---------------------------------------------------------------------------------------------\n",
    "def build_X(data, country,time_eff):\n",
    "    time_effect=time_eff\n",
    "    broad_nl = data[data['country']==country]\n",
    "    broad_nl['date_time'] = broad_nl['date_time'].astype('datetime64[m]')\n",
    "    broad_nl = broad_nl.sort_values('date_time', ignore_index = True)\n",
    "    # add columns\n",
    "    broad_nl['pos_program'] = (broad_nl['program_before']==broad_nl['program_after']).astype(int)\n",
    "    broad_nl['weekend'] = (broad_nl['date_time'].dt.weekday.values>3).astype(int)\n",
    "    broad_nl['prime'] = broad_nl['date_time'].dt.hour.between(18,23).values.astype(int)\n",
    "    broad_nl['prime_18']= broad_nl['date_time'].dt.time.between(datetime.time(18,15,0),\n",
    "                                                                   datetime.time(22, 15, 0)).values.astype(int)\n",
    "    broad_nl['prime_16']= broad_nl['date_time'].dt.time.between(datetime.time(16,0,0),\n",
    "                                                                   datetime.time(18, 15, 0)).values.astype(int)\n",
    "    broad_nl['prime_22']= broad_nl['date_time'].dt.time.between(datetime.time(22,15,0),\n",
    "                                                                   datetime.time(23, 59, 0)).values.astype(int)\n",
    "    broad_nl['post_eff'] = broad_nl['date_time'] + pd.Timedelta(minutes=time_effect-1)\n",
    "    # remove columns\n",
    "    broad_nl = broad_nl.drop(['program_before', \n",
    "                              'program_after', \n",
    "                              'program_category_before', \n",
    "                              'program_category_after',\n",
    "                              'country'], axis = 1)\n",
    "    ads_starts_nl = broad_nl['date_time'].drop_duplicates() #all ads starting times\n",
    "    # rename columns\n",
    "    broad_nl = broad_nl.rename(columns = {'length_of_spot': 'duration',\n",
    "                               'position_in_break': 'pos_break',\n",
    "                               'product_category':'prod_cat'})\n",
    "    \n",
    "    # group ads within the post-effect\n",
    "    broad_nl['ad_group'] = 1\n",
    "    gr = 1\n",
    "    for ad in range(len(broad_nl)-1):\n",
    "        time_delta = broad_nl.loc[ad+1]['date_time']-broad_nl.loc[ad]['date_time']\n",
    "        if time_delta<pd.Timedelta(minutes=time_effect):\n",
    "            broad_nl.loc[ad+1, 'ad_group'] = gr\n",
    "            continue\n",
    "        gr = gr+1\n",
    "        broad_nl.loc[ad+1, 'ad_group'] = gr \n",
    "\n",
    "    groups = broad_nl.groupby('ad_group')\n",
    "    mult = groups.size().index[(groups.size()>1).values]\n",
    "\n",
    "    # The Netherlands does not have categories for the positions in the break------------------------------------\n",
    "    if country == 'Netherlands':\n",
    "        broad_nl['pos_break'] = broad_nl['pos_break'].astype(int)\n",
    "        # Talpa TV\n",
    "        broad_nl.loc[(broad_nl['operator']=='Talpa TV') & (broad_nl['pos_break']<=2), 'pos_break'] +=1\n",
    "        \n",
    "        broad_nl.loc[(broad_nl['pos_break']>=3) & (broad_nl['pos_break']<=97), 'pos_break'] = 'Any Other Position'\n",
    "        broad_nl.loc[(broad_nl['pos_break']==1), 'pos_break'] = 'First Position'\n",
    "        broad_nl.loc[(broad_nl['pos_break']==2), 'pos_break'] = 'Second Position'\n",
    "        broad_nl.loc[(broad_nl['pos_break']==98), 'pos_break'] = 'Before Last Position'\n",
    "        broad_nl.loc[(broad_nl['pos_break']==99), 'pos_break'] = 'Last Position'\n",
    "        \n",
    "    X_nl = groups.first()\n",
    "    encoder = ce.OneHotEncoder(cols=['operator', 'pos_break', 'duration', 'prod_cat', 'channel'],drop_invariant=True, \n",
    "                               use_cat_names=True).fit(broad_nl.drop('ad_group', axis=1))\n",
    "    X_nl = encoder.transform(X_nl)\n",
    "\n",
    "    # Adjust the data for multiple ads at the same time\n",
    "    for key in mult:\n",
    "        x = groups.get_group(key)\n",
    "        x = encoder.transform(x)\n",
    "        cols = x.drop(['date_time', 'post_eff'], axis=1).columns\n",
    "        X_nl.loc[key, cols] = x.sum()[cols]\n",
    "        X_nl.loc[key,'post_eff'] = x['post_eff'].max()\n",
    "\n",
    "    X_nl['num_ads'] = groups.size().values\n",
    "    return X_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_matrix based on each advertisement individually-----------------------------------------------------------------------------\n",
    "def build_X_blocks(data, country,time_eff):\n",
    "    time_effect=time_eff\n",
    "    broad_nl = data[data['country']==country]\n",
    "    broad_nl['date_time'] = broad_nl['date_time'].astype('datetime64[m]')\n",
    "    broad_nl = broad_nl.sort_values('date_time', ignore_index = True)\n",
    "    # add columns\n",
    "    broad_nl['pos_program'] = (broad_nl['program_before']==broad_nl['program_after']).astype(int)\n",
    "    broad_nl['weekend'] = (broad_nl['date_time'].dt.weekday.values>3).astype(int)\n",
    "    broad_nl['prime'] = broad_nl['date_time'].dt.hour.between(18,23).values.astype(int)\n",
    "    broad_nl['prime_18']= broad_nl['date_time'].dt.time.between(datetime.time(18,15,0),\n",
    "                                                                   datetime.time(22, 14, 0)).values.astype(int)\n",
    "    broad_nl['prime_16']= broad_nl['date_time'].dt.time.between(datetime.time(16,0,0),\n",
    "                                                                   datetime.time(18, 14, 0)).values.astype(int)\n",
    "    broad_nl['prime_22']= broad_nl['date_time'].dt.time.between(datetime.time(22,15,0),\n",
    "                                                                   datetime.time(23, 59, 0)).values.astype(int)\n",
    "    broad_nl['post_eff'] = broad_nl['date_time'] + pd.Timedelta(minutes=time_effect-1)\n",
    "    # remove columns\n",
    "    broad_nl = broad_nl.drop(['program_before', \n",
    "                              'program_after', \n",
    "                              'program_category_before', \n",
    "                              'program_category_after',\n",
    "                              'country'], axis = 1)\n",
    "    ads_starts_nl = broad_nl['date_time'].drop_duplicates() #all ads starting times\n",
    "    # rename columns\n",
    "    broad_nl = broad_nl.rename(columns = {'length_of_spot': 'duration',\n",
    "                               'position_in_break': 'pos_break',\n",
    "                               'product_category':'prod_cat'})\n",
    "    \n",
    "    # group ads within the post-effect\n",
    "    broad_nl['ad_group'] = 1\n",
    "    gr = 1\n",
    "    for ad in range(len(broad_nl)-1):\n",
    "        time_delta = broad_nl.loc[ad+1]['date_time']-broad_nl.loc[ad]['date_time']\n",
    "        if time_delta<pd.Timedelta(minutes=time_effect):\n",
    "            broad_nl.loc[ad+1, 'ad_group'] = gr\n",
    "            continue\n",
    "        gr = gr+1\n",
    "        broad_nl.loc[ad+1, 'ad_group'] = gr \n",
    "\n",
    "    # The Netherlands does not have categories for the positions in the break------------------------------------\n",
    "    if country == 'Netherlands':\n",
    "        broad_nl['pos_break'] = broad_nl['pos_break'].astype(int)\n",
    "        # Talpa TV\n",
    "        broad_nl.loc[(broad_nl['operator']=='Talpa TV') & (broad_nl['pos_break']<=2), 'pos_break'] +=1\n",
    "        \n",
    "        broad_nl.loc[(broad_nl['pos_break']>=3) & (broad_nl['pos_break']<=97), 'pos_break'] = 'Any Other Position'\n",
    "        broad_nl.loc[(broad_nl['pos_break']==1), 'pos_break'] = 'First Position'\n",
    "        broad_nl.loc[(broad_nl['pos_break']==2), 'pos_break'] = 'Second Position'\n",
    "        broad_nl.loc[(broad_nl['pos_break']==98), 'pos_break'] = 'Before Last Position'\n",
    "        broad_nl.loc[(broad_nl['pos_break']==99), 'pos_break'] = 'Last Position'\n",
    "        \n",
    "    X_nl = broad_nl\n",
    "    encoder = ce.OneHotEncoder(cols=['operator', 'pos_break', 'duration', 'prod_cat', 'channel'],drop_invariant=True, \n",
    "                               use_cat_names=True).fit(broad_nl)\n",
    "    X_nl = encoder.transform(X_nl)\n",
    "        \n",
    "    return X_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main code to build all different X_matrices that are needed\n",
    "\n",
    "# Start with the advertisement groups for different time_effects: [1,2,...,10]\n",
    "for time_effect in range(1,11):\n",
    "    X_nl = build_X(broadcasting_data, 'Netherlands', time_effect)\n",
    "    X_nl.to_csv(direct+r'\\X_matrix\\X_nl_'+ str(time_effect) + 'min.csv', index_label='ad_group')\n",
    "    \n",
    "    X_be = build_X(broadcasting_data, 'Belgium', time_effect)\n",
    "    X_be.to_csv(direct+r'\\X_matrix\\X_be_'+ str(time_effect) + 'min.csv', index_label='ad_group')\n",
    "    \n",
    "# 4 minutes seems best, so for the blocks method, we only make the dataset based on 4 minutes\n",
    "time_effect = 4\n",
    "X_nl = build_X_blocks(broadcasting_data, 'Netherlands', time_effect)\n",
    "X_nl.to_csv(direct+r'\\X_matrix\\X_nl_'+ str(time_effect) + 'min_blocks.csv', index_label='ad_group')\n",
    "\n",
    "X_be = build_X_blocks(broadcasting_data, 'Belgium', time_effect)\n",
    "X_be.to_csv(direct+r'\\X_matrix\\X_be_'+ str(time_effect) + 'min_blocks.csv', index_label='ad_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the different datasets of the visits_index per case:\n",
    "time_effect = 4\n",
    "for idx, traffic_data in enumerate(traffic_datasets):\n",
    "    case = idx+1\n",
    "    \n",
    "    nl_app = prep_data(traffic_data, broadcasting_data, 'Netherlands', 'app', time_effect)\n",
    "    nl_web = prep_data(traffic_data, broadcasting_data, 'Netherlands', 'website', time_effect)\n",
    "    be_app = prep_data(traffic_data, broadcasting_data, 'Belgium', 'app', time_effect)\n",
    "    be_web = prep_data(traffic_data, broadcasting_data, 'Belgium', 'website', time_effect)\n",
    "\n",
    "    nl_app.to_csv(direct+r'\\visits\\nl_app_case' +str(case) + '_4min.csv')\n",
    "    nl_web.to_csv(direct+r'\\visits\\nl_web_case' +str(case) + '_4min.csv')\n",
    "    be_app.to_csv(direct+r'\\visits\\be_app_case' +str(case) + '_4min.csv')\n",
    "    be_web.to_csv(direct+r'\\visits\\be_web_case' +str(case) + '_4min.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
